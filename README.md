# ðŸš€ RKE2 + Cilium (Strict Mode) + LB-IPAM & L2 Announcements Kurulumu

Bu dokÃ¼man, **RKE2 Kubernetes** kÃ¼mesini kube-proxyâ€™siz (`strict` mode) olarak **Cilium** ile Ã§alÄ±ÅŸtÄ±rÄ±p;

* Ä°stediÄŸimiz **sabit LoadBalancer IP**â€™lerini atamayÄ±,
* **L2 Announcements** ile bu IPâ€™leri aÄŸda ARP/NDP Ã¼zerinden duyurmayÄ±,
* Ve gÃ¼venlik politikalarÄ± ile trafik kontrolÃ¼ saÄŸlamayÄ± adÄ±m adÄ±m gÃ¶sterir.

ðŸ’¡ **Hedef:** MetalLB gibi ek bileÅŸenlere gerek kalmadan, **Layer-2** segmentindeki cihazlardan doÄŸrudan eriÅŸilebilir servisler oluÅŸturmak.

---

## ðŸ“Œ Ä°Ã§indekiler

1. [RKE2 Kurulumu](#-rke2-kurulumu)
2. [Cilium Kurulumu](#-cilium-kurulumu)
3. [Metrics & Hubble UI YayÄ±nÄ±](#-metrics--hubble-ui-yayÄ±nÄ±)
4. [Network Restriction Ã–rneÄŸi](#-network-restriction-Ã¶rneÄŸi)
5. [Cilium LB-IPAM & L2 Announcements](#-cilium-lb-ipam--l2-announcements)
6. [Demo ve SonuÃ§](#-demo-ve-sonuÃ§)

---

## ðŸ›  RKE2 Kurulumu

```bash
sudo mkdir -p /etc/rancher/rke2
```
```bash
sudo tee /etc/rancher/rke2/config.yaml > /dev/null << 'EOF'
write-kubeconfig-mode: "0644"
node-ip: "10.20.56.30"
disable:
  - rke2-canal
  - rke2-ingress-nginx
disable-kube-proxy: true
tls-san:
  - "10.20.56.30"
EOF
```
```bash
curl -sfL https://get.rke2.io | INSTALL_RKE2_TYPE=server sh -
```
```bash
systemctl enable rke2-server --now
```
```bash
sudo systemctl start rke2-server.service
```
```bash
export KUBECONFIG=/etc/rancher/rke2/rke2.yaml
```

![RKE2 Status](./img/rke-status.png)

Podâ€™larÄ±n Pending durumda kalmasÄ±nÄ±n sebebi, kÃ¼mede henÃ¼z bir CNI (Container Network Interface) eklentisinin kurulu olmamasÄ±. RKE2, varsayÄ±lan CNIâ€™si devre dÄ±ÅŸÄ± bÄ±rakÄ±ldÄ±ÄŸÄ± iÃ§in (Ã¶r. rke2-canal), podâ€™lar gerekli aÄŸ yapÄ±landÄ±rmasÄ±na ulaÅŸamÄ±yor ve baÅŸlatÄ±lamÄ±yor. 
---

## ðŸ Cilium Kurulumu

Prometheus CRDâ€™lerini yÃ¼kleyelim:

```bash
kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
```

Helm ile Ciliumâ€™u yÃ¼kleyelim:

```bash
helm upgrade --install cilium cilium/cilium \
  --version 1.18.0 \
  --namespace kube-system \
  -f cilium-values.yaml
```

![Helm Install](./img/helm-install.png)

---

## ðŸ“Š Metrics & Hubble UI YayÄ±nÄ±

VarsayÄ±lan servisleri temizleyip, NodePort ile dÄ±ÅŸa aÃ§alÄ±m:

```bash
kubectl delete svc cilium-agent -n kube-system
kubectl delete svc hubble-metrics -n kube-system

kubectl apply -f cilium-metrics-nodeport.yaml -n kube-system
kubectl apply -f hubble-metrics-nodeport.yaml -n kube-system
```

![NodePort Services](./img/nodeport.png)

* **Metrics URLâ€™leri:**

  * [http://10.20.56.30:30861/metrics](http://10.20.56.30:30861/metrics)
  * [http://10.20.56.30:30965/metrics](http://10.20.56.30:30965/metrics)

(Bu endpointâ€™ler Prometheusâ€™a hedef olarak eklenip Grafana Ã¼zerinden gÃ¶rselleÅŸtirilebilir.)

* **Hubble UI:**

  [http://10.20.56.30:31647](http://10.20.56.30:31647)

---

## ðŸ”’ Network Restriction Ã–rneÄŸi

Namespaceâ€™leri oluÅŸturalÄ±m:

```bash
kubectl create ns client-ns
kubectl create ns nginx-ns
```

Podâ€™larÄ± deploy edelim:

```bash
kubectl apply -f client.yaml -n client-ns
kubectl apply -f nginx.yaml -n nginx-ns
```

Restrict kuralÄ±nÄ± ekleyelim:

```bash
kubectl apply -f restrict-rule.yaml
```

Clientâ€™tan eriÅŸim test edelim:

```bash
kubectl -n client-ns exec -it client -- curl nginx.nginx-ns.svc.cluster.local
```
GÃ¶rselde gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ gibi trafik akÄ±ÅŸÄ±nda hiÃ§bir sorun yok.
![Allow Traffic](./img/allow.png)

Åžimdi Restriction rule unu test etmek iÃ§in Attacker namespace oluÅŸturalÄ±m:

```bash
kubectl create ns attacker-ns
```
```bash
kubectl run -n attacker-ns attacker --rm -it --image=alpine -- sh
apk add curl
curl nginx.nginx-ns.svc.cluster.local
```
GÃ¶rselde gÃ¶rdÃ¼ndÃ¼ÄŸÃ¼ gibi restriction iÅŸe yaradÄ± ve istek drop oldu. Nginx pod una sadece client gelebiliyor.
![Drop Traffic](./img/drop.png)

---

## ðŸŒ Cilium LB-IPAM & L2 Announcements

Ä°stediÄŸimiz sabit IPâ€™leri atamak iÃ§in havuz oluÅŸturalÄ±m:

```bash
kubectl apply -f ip-pool.yaml
```

![CiliumLoadBalancerIPPool](./img/CiliumLoadbalancerIPPool.png)

L2 duyurum politikasÄ±nÄ± ekleyelim:

```bash
kubectl apply -f cilium-l2ann-policy.yaml
```

![L2 Announce](./img/l2announce.png)

---

## ðŸ§ª Demo ve SonuÃ§

Demo namespace:

```bash
kubectl create ns lb-demo
kubectl apply -f deploy.yaml -n lb-demo
```

![LB Service](./img/lb-svc.png)

TarayÄ±cÄ± ve curl Ã§Ä±ktÄ±sÄ±:
![Curl Test](./img/curl.png)
![Browser Test](./img/browser.png)

---

## ðŸŽ¯ Ã–zet

Ciliumâ€™un **LB-IPAM** Ã¶zelliÄŸi ile servislerimize istediÄŸimiz **sabit LoadBalancer IP**â€™lerini atayacaÄŸÄ±z.
**L2 Announcements** sayesinde bu IPâ€™leri aÄŸda ARP/NDP Ã¼zerinden duyurarak, aynÄ± Layer-2 segmentindeki cihazlarÄ±n doÄŸrudan eriÅŸmesini saÄŸlayacaÄŸÄ±z.
BÃ¶ylece MetalLB gibi ek bileÅŸenlere gerek kalmadan, kontrol tamamen elimizde olacak ÅŸekilde kÃ¼me dÄ±ÅŸÄ± eriÅŸim saÄŸlayacaÄŸÄ±z.
